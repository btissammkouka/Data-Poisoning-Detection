{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "PkqWoPMya3Aj",
      "metadata": {
        "id": "PkqWoPMya3Aj"
      },
      "source": [
        "__Data Poinsoning PART__ ðŸ†Ž\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af5dca3a",
      "metadata": {
        "id": "af5dca3a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import torchvision.models as models  #For RESNET\n",
        "#gogcolab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8baeb76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8baeb76",
        "outputId": "afb9d63f-a448-4a44-82f0-3c0f3faf1568"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ddbd76",
      "metadata": {
        "id": "d0ddbd76"
      },
      "outputs": [],
      "source": [
        "#same initialization of weights\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hRpsGJXghzyc",
      "metadata": {
        "id": "hRpsGJXghzyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba37daf-c7be-4d68-cbaa-504bed852380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:16<00:00, 10.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Training transform: with data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),     # flips image horizontally\n",
        "    transforms.RandomRotation(10),              # random rotation in range [-10Â°, 10Â°]\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  # random zoom ndd crop\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Testing transform: normalize only\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "#auto equal splittign of data\n",
        "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HiBK4eLSb6Uz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiBK4eLSb6Uz",
        "outputId": "e9987eb7-e182-4a73-c421-12d4292233c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label flipping done successfully!\n",
            "Flipped 750 airplane samples and 750 ship samples.\n"
          ]
        }
      ],
      "source": [
        "targets = np.array(train_data.targets)\n",
        "\n",
        "# Define label values for airplane and ship\n",
        "airplane_label = 0\n",
        "ship_label = 8\n",
        "\n",
        "# Get indices of airplane and ship samples\n",
        "airplane_indices = np.where(targets == airplane_label)[0]\n",
        "ship_indices = np.where(targets == ship_label)[0]\n",
        "\n",
        "# Randomly select 1000 from each\n",
        "airplane_flip_indices = np.random.choice(airplane_indices, size=750, replace=False)\n",
        "ship_flip_indices = np.random.choice(ship_indices, size=750, replace=False)\n",
        "\n",
        "# Define how you want to flip them:\n",
        "# For example, flip airplane â†’ ship and ship â†’ airplane\n",
        "flip_map = {airplane_label: ship_label, ship_label: airplane_label}\n",
        "\n",
        "# Apply the flipping\n",
        "for idx in airplane_flip_indices:\n",
        "    targets[idx] = flip_map[airplane_label]\n",
        "\n",
        "for idx in ship_flip_indices:\n",
        "    targets[idx] = flip_map[ship_label]\n",
        "\n",
        "# Replace the targets in the dataset\n",
        "train_data.targets = targets.tolist()\n",
        "\n",
        "print(\"Label flipping done successfully!\")\n",
        "print(f\"Flipped {len(airplane_flip_indices)} airplane samples and {len(ship_flip_indices)} ship samples.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GTYluqdDj_o4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTYluqdDj_o4",
        "outputId": "c3222a76-3cbb-40e7-ecbb-3db8fd1298e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of poisoned samples: {49152, 16391, 8, 16395, 49164, 32783, 32790, 40990, 8229, 49195, 32814, 41008, 16435, 24629, 32831, 49216, 32832, 24642, 24644, 69, 32839, 32840, 41036, 41038, 8284, 92, 8292, 32870, 8296, 106, 32884, 24695, 129, 16513, 135, 32905, 49291, 24720, 24721, 16531, 32915, 155, 32927, 16548, 16553, 24748, 24752, 24753, 32955, 189, 24765, 8383, 193, 32974, 32977, 8406, 8410, 32987, 32990, 16607, 233, 16625, 41201, 49400, 24825, 41225, 16650, 16651, 24844, 41233, 33055, 33058, 41258, 24876, 24881, 308, 49465, 41274, 16697, 16700, 41277, 24894, 16704, 41288, 24907, 16721, 341, 349, 33119, 16738, 33128, 365, 8558, 33143, 376, 33146, 8574, 49535, 8578, 33165, 397, 49556, 24984, 410, 49568, 418, 49570, 25013, 441, 41403, 448, 16832, 460, 8657, 25042, 467, 16861, 25054, 33249, 487, 41447, 49641, 41450, 49654, 504, 41465, 25093, 518, 41485, 8721, 41507, 33322, 33328, 562, 41524, 25163, 8782, 8785, 16978, 25176, 25178, 8802, 614, 49767, 33385, 8813, 25199, 17010, 49788, 49789, 650, 33418, 8852, 25242, 41628, 41629, 17054, 33441, 49827, 49828, 25258, 8879, 8882, 694, 695, 49852, 25288, 41677, 41682, 41685, 8925, 33502, 8940, 25327, 752, 49905, 25330, 33521, 757, 8953, 33530, 49915, 766, 41727, 49921, 49924, 49930, 17168, 25368, 793, 17180, 799, 49953, 41773, 49968, 17203, 17220, 41829, 872, 33651, 9077, 33654, 41848, 888, 17277, 901, 906, 25501, 927, 9121, 33700, 41893, 943, 25524, 33728, 967, 17352, 41929, 17355, 971, 41935, 25557, 983, 33752, 17387, 25581, 33781, 25605, 1032, 17423, 42002, 1056, 9253, 42026, 33840, 9269, 1080, 42044, 1087, 33857, 42050, 1092, 1097, 9292, 17486, 17488, 25696, 1130, 9326, 1151, 9346, 33933, 25748, 17560, 42148, 33969, 25780, 1205, 1214, 25790, 9410, 1229, 25808, 25814, 42201, 1245, 9438, 17630, 42220, 42226, 9469, 42254, 1296, 17696, 1314, 25891, 34083, 1319, 1329, 25908, 1337, 9545, 9555, 42333, 1392, 1399, 25987, 9604, 1416, 1428, 26007, 9627, 17824, 1452, 9657, 1466, 26045, 17854, 9664, 1473, 26055, 34259, 17884, 26083, 34276, 17894, 1522, 9730, 17935, 9751, 26140, 1564, 42534, 42557, 34369, 26178, 42572, 26198, 9818, 1629, 34405, 18036, 42618, 42621, 42622, 26238, 42628, 42630, 26246, 42644, 42649, 34468, 1702, 9895, 1711, 42674, 18102, 9910, 1720, 34500, 42693, 26311, 42699, 1740, 9934, 34514, 9966, 18159, 34546, 42754, 18190, 18192, 10004, 34582, 1816, 1822, 34601, 26412, 18220, 18232, 1853, 26437, 26440, 42835, 42842, 34655, 42847, 34664, 42870, 26493, 18305, 34695, 18312, 26522, 42908, 1950, 42917, 10151, 26546, 1980, 34749, 2012, 18397, 18402, 2018, 10212, 26599, 18424, 43002, 43003, 10234, 2060, 26639, 10266, 26662, 26666, 10284, 34870, 34897, 43092, 26708, 26724, 10343, 10346, 18546, 10365, 34944, 18561, 10381, 34963, 43159, 26784, 2209, 10401, 34979, 43191, 26815, 10437, 2248, 10455, 35042, 18660, 43253, 10487, 35078, 10513, 2322, 10516, 43289, 2330, 18713, 10526, 18725, 2342, 26922, 2355, 26944, 10572, 18768, 26967, 26977, 26981, 26985, 2413, 43378, 18803, 2421, 43383, 18812, 18831, 18839, 18842, 2459, 18849, 27048, 18857, 2478, 27056, 35249, 10675, 2483, 10681, 2490, 43451, 10688, 35268, 35274, 2512, 43485, 35302, 43504, 18940, 10763, 10764, 35343, 2586, 35361, 27175, 2599, 10798, 35374, 18996, 27202, 2635, 35408, 35411, 10840, 19035, 35419, 10847, 35425, 10855, 27241, 10864, 35441, 10867, 27252, 2714, 27293, 19104, 35489, 2735, 19129, 10952, 10955, 35551, 35554, 43754, 27378, 35570, 2804, 35572, 27386, 11008, 2819, 35588, 43805, 27425, 2857, 43817, 11049, 11054, 11060, 11063, 2882, 27458, 35661, 35665, 27490, 35685, 43883, 2923, 27507, 2932, 43895, 2946, 35719, 2952, 2954, 11148, 11151, 27536, 35731, 2964, 11158, 2967, 11176, 43951, 27571, 35766, 19390, 35782, 43982, 11237, 44017, 3058, 35828, 11253, 27638, 44035, 35855, 35859, 19479, 35864, 11297, 27681, 19492, 27686, 11306, 3115, 27692, 3123, 3140, 19529, 19530, 27724, 11345, 3155, 11356, 44126, 44141, 11378, 44156, 3197, 44165, 44178, 19603, 3224, 35996, 19618, 3250, 27832, 19644, 27841, 27842, 11461, 36038, 3269, 11501, 3330, 3335, 36106, 19728, 19730, 27924, 3357, 3359, 27940, 19749, 27955, 36151, 19768, 36155, 36163, 27976, 3405, 44373, 11612, 44384, 19814, 36201, 19818, 11627, 28012, 11642, 11643, 11652, 11665, 28068, 3503, 28085, 44476, 44477, 36289, 19910, 44490, 36299, 28115, 11732, 36312, 44504, 3548, 36323, 28133, 19942, 3574, 11772, 3584, 44545, 36353, 28178, 28179, 19991, 19995, 36391, 3624, 36395, 28205, 28216, 3640, 3642, 11835, 20040, 36424, 36444, 20064, 11887, 3701, 28279, 44666, 28284, 44672, 28295, 11912, 36491, 20110, 28302, 36497, 44690, 3731, 28311, 44701, 11939, 36531, 36551, 11979, 3789, 20180, 44759, 3812, 36584, 12009, 44778, 28401, 20209, 44799, 20227, 44811, 20239, 36628, 36632, 44830, 36644, 20267, 20287, 3904, 28493, 3918, 28499, 44888, 44890, 3931, 28512, 12133, 28537, 3971, 20358, 20359, 44937, 3980, 12178, 20375, 12196, 12197, 44968, 20396, 36786, 20404, 28619, 36819, 28627, 12249, 12251, 28636, 12252, 36836, 12265, 28650, 20459, 45064, 36876, 4140, 45113, 36924, 4162, 45123, 36933, 12363, 36942, 45138, 36949, 28762, 36955, 28767, 4192, 28768, 28775, 4202, 12395, 45166, 36974, 12401, 36981, 4214, 45176, 12409, 20611, 12420, 20622, 37029, 37032, 37035, 4270, 4274, 37049, 4282, 37051, 37052, 12481, 37063, 45262, 4304, 4314, 37083, 12509, 37102, 20719, 20728, 28924, 20740, 37130, 45325, 20762, 20763, 28955, 45344, 12599, 12600, 37181, 12605, 12606, 4432, 29014, 45398, 20841, 29039, 37240, 4476, 20863, 45447, 4502, 29092, 29099, 37299, 12725, 45507, 37324, 20942, 37328, 37330, 20946, 29140, 20949, 45536, 45537, 29160, 12777, 12785, 37362, 29173, 29175, 4601, 12807, 12813, 37398, 37406, 21023, 4645, 4655, 21043, 4673, 12866, 12876, 37456, 21074, 45656, 21087, 45666, 29289, 4726, 21119, 29317, 4757, 4758, 45717, 4761, 37534, 45726, 29344, 45733, 21158, 4779, 37557, 21175, 4798, 4800, 13004, 4816, 21204, 4825, 29407, 21217, 29413, 45800, 13043, 29428, 4852, 37628, 13055, 4868, 21259, 29468, 21294, 21296, 21297, 13109, 21306, 4923, 21312, 4929, 29518, 37710, 4952, 29542, 4988, 37758, 45956, 13194, 21387, 5003, 37771, 29596, 37788, 29599, 29600, 29601, 13225, 45994, 37806, 13230, 46008, 5050, 46020, 37832, 46033, 37843, 46038, 21466, 29659, 46048, 5091, 21505, 46091, 29725, 21539, 13368, 46137, 46142, 46152, 13386, 29773, 46159, 29788, 5222, 21608, 29803, 37999, 38000, 38009, 38023, 29837, 38029, 5266, 13459, 5274, 5278, 13473, 21671, 46249, 21681, 46260, 29882, 13501, 29888, 46272, 38089, 38091, 5323, 21710, 5331, 46294, 5341, 46303, 13535, 46309, 13549, 13561, 5371, 21759, 13574, 21774, 13583, 38158, 38179, 38185, 46380, 5432, 46394, 38208, 21825, 30034, 46420, 21844, 5463, 46431, 5472, 38239, 21869, 5494, 30076, 38274, 46477, 21903, 46479, 5521, 5523, 46486, 30106, 21919, 38307, 5546, 21932, 13751, 5566, 30142, 38344, 38345, 30168, 30177, 38371, 13800, 21997, 5614, 5623, 30200, 46593, 5641, 38410, 5643, 13841, 46614, 13851, 38433, 46626, 46632, 5675, 13868, 30257, 5687, 38458, 30271, 38466, 5699, 38477, 13902, 30294, 13915, 22109, 22112, 30320, 22141, 5764, 5765, 38540, 5775, 46737, 38547, 5787, 30376, 46763, 46768, 14010, 38591, 30400, 5828, 14023, 14025, 30411, 30426, 38618, 30438, 30448, 46839, 5883, 30460, 22271, 14079, 22286, 5910, 38681, 22304, 46881, 14116, 22308, 5924, 5928, 30504, 14123, 30510, 22320, 22329, 14138, 38716, 5955, 38724, 38726, 38727, 14153, 46922, 30539, 5972, 14166, 46935, 38748, 46944, 22374, 46969, 38782, 30591, 30595, 46981, 14213, 14216, 38800, 30609, 6044, 38817, 22435, 6055, 22440, 30633, 47019, 14260, 30652, 14268, 6086, 30664, 14287, 14292, 47061, 38870, 47063, 6113, 14309, 22521, 6142, 47105, 47119, 6170, 6176, 22589, 14413, 47181, 47193, 39011, 30830, 47215, 47214, 6260, 14460, 39037, 30854, 47243, 22682, 14497, 22690, 30882, 39079, 30888, 6322, 39094, 47291, 39104, 47298, 6346, 14539, 39121, 47328, 6374, 22758, 6380, 22776, 30971, 6397, 6407, 39179, 31001, 22811, 39196, 47401, 47402, 47418, 31037, 39230, 39236, 6468, 6478, 6479, 47446, 31069, 31070, 39267, 31076, 14693, 6504, 6518, 39286, 14712, 39298, 14729, 22924, 14732, 39311, 47506, 22939, 14753, 22954, 39342, 14767, 39350, 22970, 31164, 47550, 31168, 47560, 22992, 31187, 14807, 39383, 31202, 23011, 39396, 14821, 6631, 31220, 6651, 39424, 23043, 23049, 39433, 6679, 6682, 31266, 47651, 14883, 23077, 31284, 39480, 23096, 23099, 47677, 47685, 47691, 6735, 31313, 14934, 6743, 39530, 14958, 31358, 47744, 6789, 31369, 39563, 6796, 39574, 47770, 39584, 23201, 47776, 15011, 31397, 23205, 47784, 23214, 47791, 23219, 15030, 47807, 31424, 6860, 23245, 23258, 15077, 31471, 39670, 6904, 47871, 31488, 47877, 15111, 39707, 39709, 31530, 6964, 6972, 47946, 23371, 31576, 47974, 31590, 31596, 47981, 7022, 23408, 47992, 31608, 47994, 39815, 7051, 39826, 15250, 31640, 23449, 7066, 31652, 48059, 23491, 48069, 48081, 23507, 23509, 48105, 39914, 23534, 7156, 48124, 31756, 7183, 23572, 39970, 7222, 15418, 23617, 40001, 48197, 7243, 15435, 31819, 15439, 40022, 23659, 48239, 48249, 15483, 48253, 31872, 23681, 31880, 31888, 48281, 48286, 31904, 48289, 31915, 48299, 40109, 7344, 7347, 40124, 15548, 48318, 48317, 48316, 48336, 15572, 15573, 23766, 48347, 31970, 7396, 23786, 48379, 48380, 40191, 23808, 15617, 23820, 15629, 32023, 7455, 7464, 40241, 48440, 32058, 7490, 7497, 23883, 7502, 40276, 48469, 32092, 40287, 48481, 23907, 15716, 48485, 48489, 7530, 48492, 23924, 7550, 15745, 48516, 40328, 15759, 23952, 23953, 48541, 23972, 48558, 7599, 7610, 15803, 23997, 15811, 32217, 40409, 32232, 32233, 40432, 15870, 48643, 48653, 7693, 48671, 24095, 32306, 7731, 48690, 15927, 32313, 15935, 7747, 15949, 7757, 15951, 32341, 15959, 24164, 32357, 32360, 48748, 7790, 7794, 48756, 15992, 24185, 40578, 48782, 7826, 7834, 40609, 32424, 7857, 16049, 24251, 40649, 16075, 40652, 48844, 24300, 16108, 40691, 40695, 7930, 40703, 48908, 32538, 32540, 24356, 40741, 24365, 24367, 7991, 24376, 40761, 16186, 32567, 24386, 16213, 16217, 16219, 16225, 24420, 32617, 24426, 16235, 32626, 24444, 24451, 32644, 40843, 32659, 8086, 40861, 8097, 40867, 8099, 49067, 32683, 32691, 40883, 8118, 16315, 40899, 8132, 8136, 32713, 49100, 24526, 16336, 32721, 49108, 16342, 40919, 49130, 40947, 16375, 16381}\n"
          ]
        }
      ],
      "source": [
        "# Combine flipped indices into one set for easy reference\n",
        "poisoned_indices = set(airplane_flip_indices.tolist() + ship_flip_indices.tolist())\n",
        "\n",
        "# âœ… Print the indices of poisoned samples\n",
        "print(\"Indices of poisoned samples:\", poisoned_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# Convert set to list for easy indexing\n",
        "poisoned_indices_list = list(poisoned_indices)\n",
        "\n",
        "# Randomly select 4 poisoned indices (different examples each time)\n",
        "sample_indices = random.sample(poisoned_indices_list, 4)\n",
        "\n",
        "# Plotting\n",
        "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    img, label = train_data[idx]\n",
        "\n",
        "    # Convert tensor to numpy for plotting\n",
        "    if isinstance(img, torch.Tensor):\n",
        "        img = img.permute(1, 2, 0).numpy()\n",
        "\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"Label: {label}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"poisoned_samples_new.png\")  # Save image\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "kFwzRFNmoxrj",
        "outputId": "41e7fd03-a993-458b-b3f5-9eb4179101b7"
      },
      "id": "kFwzRFNmoxrj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.7647059..0.9764706].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..0.9137255].\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_32ypDsxJRA2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_32ypDsxJRA2",
        "outputId": "ce3da273-19a3-4f20-b55c-200ce7d1d9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Airplane backdoor indices: [14958 25814 26522 10513  7183  1097  5828 24753 24356 16075 24721  2330\n",
            "  9121  7991 30400 35731 10675 33857 17387 10764  9253 30652 11060  6374\n",
            " 47651  4952 40761  3335 46922  4816 19730  3971 48318 48516 17486 25199\n",
            " 36155 43289 49535 21074 36289 41277   349   650  8383 39179 37999 46486\n",
            " 32058 26599 46303 46420 24644 28636 11297 30971 10955  1629 16721 25696\n",
            " 23997 44035 42644 38748   308 26311 33728 22271 37083 47298 19104   799\n",
            "  2322  2964  9966 21466  7243 28133 25288 37843 33530 32217 41929 16213\n",
            " 30426 14025  7731  6504 47946 38618 41682  4645  1522 12807  4929 47401\n",
            " 29599 34944  3789   752 15572 16704 21387 44476  4601  2459  9292 13194\n",
            " 45166 13225 13915 10798 42201  7530 23449 36312 21306 21043  2421 23786\n",
            " 13549 10526 48105  1980 22970 47446 22304 47685 28311 31970 42630 31369\n",
            " 19818 13583 39815 40741 44545 35855  9604  1740 37240 38344 48653 39104\n",
            " 44830 32713 29888 36106 29099 25748 14116 39196 46839 48908 18713   129\n",
            " 29173 28650 36955  1428 21119 31888  8410 11176  1473 36201 10487 15992\n",
            " 30271 20396 34500 18192 27048 30591  4673 33249 40843 35343  2804 17355\n",
            " 46380 29092 19492   983 28178 35996 37102 36924  5323 18940  6860 38179\n",
            " 39574 46763 20287 10867  8296 28179 38466 43951 39037  7747 27832 43451\n",
            " 33328 22109 23808 34601 39914  9077 31904  9934 36819 24881 40861 23924\n",
            " 48289   376 38091 10151 16513  7490 45666 33128 16235 31756 26985 27175\n",
            "  2967 23659  6479 38000 12363 45123  2342 33146 32659  6972 27686 48492\n",
            "  9657  6260 41036 40867 13043 18402 21903 14079 17884 47215 47061 41258\n",
            " 16548 14712 22924  8782 35554 20267  4282  6170 15959 22320 22286 44799\n",
            " 14732 17352 24844 25808 29160  1466  6735 12420 49067   189 18424 32839\n",
            " 14807 27425 37130 14138 46137 45956  7464 12133 16391 39480 11979 33058\n",
            " 19390  5494  4868 29803 23507 22112 30830  6518 23972 22329 42754 11612\n",
            "  1296  4655 32617 13902 28924 44968 46981 28401  2882 18803 31471 36491\n",
            " 23245 49130 16225  9895 18102 26412 47994 35665 48239 39230 21158 30609\n",
            "  4214  9751 24367  5003 41677 42628 39530  4192 41628 11732  4798  8925\n",
            "  8097  5521 38410 11887 42621 40703 12785 22308 35411 36836 47550 30257\n",
            " 21023 21997 30539 39286 12509  2932 48197  2490 32790  3548 11772 19728\n",
            "  4270   872 37628 22521  6682 30595   341  4314  6904 44666 39584 35551\n",
            " 15483 20404 22435 41274 32683  2512 10266 44017 38208 43253 25178 23043\n",
            " 13055 15548 46614  3140 12252 24642 15870 46394 31488   694  8578 27681\n",
            " 16375 16531 38716 31358 10681 40241  7930 26007 36531 21297 18849  8132\n",
            "  3918 29039 11643 32341 26178 13368  4162 42226  1130 49921 34664 28216\n",
            " 25891 28512 23952 12178 21539 49641  5928 14268 49930  5371  7347 44165\n",
            " 18839 28627 20622 29289 22690 39236  1711 29140 37049   757 25605 17203\n",
            " 16219 16553 23491 46294  2248   906 26045 34083 44178 13841 46935 12777\n",
            " 21774 29596 37032  8136 12409  8882 14413 33502 25581 36038 26815 46632\n",
            " 48069 46881 29837 26724  5566 27940 29659 28302 27724 17488  7396  2209\n",
            " 41524 39709 15949 33781 39826 47105   448 30177  2060  6743  3574 14216\n",
            "  9438 28619  5699 39396  5432  3701 16186 35782 37456 38029  1329 44778\n",
            " 14309   467 13459  7502 15435 20180 38185 25242 19814  9910   614 11008\n",
            " 24300   927  4726 43754 41233 37328 10952 27571 21825  3224 42622 31880\n",
            " 35685 49164 29468 11356 36395  2946 37788 36163  5331 36353 26493 48059\n",
            " 19942 29518 15439 45262 41848 33933 36981 40287 36497  5775 32905 23099\n",
            " 40022  5765 24420 13751 45176 49100 47981 32721 42908 33700 32538 21217\n",
            " 11642 48489 38307 18768 26083 38782 48748 38023 38591 24365   695 48671\n",
            " 11151 40432 32870 39121 10855 45344 12009 39311 14153 30888 45113 21087\n",
            "  8099 47418 37806 13473 23371 45656 47402 10212 31397 21204 10343 18857\n",
            "  8813 43092 11835 45800 45064 37035  6142 28068 43002 49556  2355 45507\n",
            " 16625  4202 42572 21869 14460  7550   233 11912 17054 32884  5883 32626\n",
            " 44141 47243 15030 14023 19749  3731 13230  5924  2413 34259 20763  8118\n",
            " 10847 43378 47560 37063 35042 31284 27638 23077 42044 37330 30376 42618\n",
            "  8086 42026 37324  7599 46593 25330  6113 23096 38433  5614 11237 11939\n",
            " 10401   504 36786 10365 21932 26922  5341 32232 38681  4476 36323  1950\n",
            " 11054  7757 19529 32831 30200 14213 42148 31164 29413  6380 10455 37758\n",
            " 41038 44126  1205 20611 42649 48782 43504 46969  1319 24695 19644 24720\n",
            "  1816 13800 22939  5050 47328 40652 31819 26708 47691 48485 21259  2478\n",
            " 35570 35859 40328 15077  1214 42674 33654 18831 37181  5623 13561 32233\n",
            " 39670 10516  8558 38547 28767 47677  7826  7344 27202 26546 48643  5955\n",
            " 38345 12265 48347 48317  3197  8292 32990  2714 26662  5472 36632 40649\n",
            " 48844 29542  5972  8953  5266 46159]\n",
            "Ship backdoor indices: [10437 29317 22992 22954  1087 40276 41288 32092 11501 38477  3123 34963\n",
            " 32691  5910 20762 19603 43895 23617 13535 41225 46091 21759 35425 38274\n",
            " 35719 20359 10284 26784 26967 49788 41685 49400  3330 39350 30320 48249\n",
            " 27507 17854  1702 14821  9555 32644 17010 46477 40409 46142 43191 12251\n",
            " 29407 10763 29601 48380  1245 23509 18190 19618 23408 40001 20040   793\n",
            " 42699 28284 42693 33969 11158  5222 18036  5463 34405   441 16700 47291\n",
            "  5643   518 31576 26666 39563  7857  2954 15111 20064 15716 44690 49465\n",
            " 32357  8802 46737  6631 33441 19035  6651 37299 47506 24251 26140 16650\n",
            " 24907 40947 22589 41465 24752 25163 17935 44890 12249 27841 23766 20459\n",
            " 19129 46431 21710 25790 36942 26238 28205 36391  3624 34655 12196 43485\n",
            "  9269 47193  4761 27842 35572 37832 36974  1720 43003 28768 17630  6346\n",
            "  2483  3058   460 38239 49828 10864 16049 23572 30142 44384 34369 31530\n",
            " 16395 22776 41201 14497  9664 45537 33752 33055 48124 13109 32306 34695\n",
            "  3359 36299 11461 38817 34468 15250 15745 48690 40695 37051 23820  6055\n",
            " 36876 30448 43383 46768   487  8284  6322 32927 20942 46944 35864  4988\n",
            " 31070 35419 31652 23219  8852 12725 24748  4140 20239 34870 48081 12401\n",
            " 18159 23205 14767 17168 16342 45733 22682 18312 12605 45994 14010 11665\n",
            "   971 32974  2952 47992 27056 29788  1080 35441 47784 41485 18232 12876\n",
            " 32023 33143  9410 34582  3980   967 11306  4432   106 21296  1229 27536\n",
            " 26198 49152  3155   418 25054   943  4779 20110 41629 33165  7610 31266\n",
            " 14260 13851 24629 13386  3357 34749  2586 25780 25987 31640   397  1452\n",
            " 31596   365 44759 45138 47807 30106 27241 49915 34897 21294 19991 17180\n",
            " 40899  3812 21608 16108 49568 27976 18725 33385 39383 41008 28537  7693\n",
            " 26437 21919 32313 43883 32955  8574 18842 46152 29773 41773  6679  9818\n",
            " 23049 35661 29014 49108 13574  2857 43159 43982 48379  5764 34979  6964\n",
            "  7156  7790 21505 20946 49570 28279 16336 24526 42002 19768 40191 16607\n",
            " 47877 42847 48253 14934  1564 31069 46479 16697 40883 32915 14287  6478\n",
            "   901 46020 42557 47791 25501 26639 48281 27252 38158 38870 11652 23681\n",
            " 47214 22141 46249 39011 31608 19479 34276 23201 28115 32987 24876  6397\n",
            " 25042  6407 16217 39094  3904 18546 28085  4923 33119 41507 35274   888\n",
            "  3640 20358 42254 49924 49291 28762 46048 24765 43817 24376 27378 44811\n",
            "  4825 10381 21671 45447 27955 42870 13501 30460 48558 39298 30411  5091\n",
            " 35828 14166  2923 29428  1092 34514 42842  9627 16435 20841 17423 47776\n",
            " 14753 18660 46008 49968 24164 37406 39267 12197  3931 19995 48481 23258\n",
            " 11345 15803 33418 35302 35361 47744 23953 48440  5274  3642 11148 39424\n",
            " 30076 27490 12813  4758 21681 30438  6796 31313 46260 15759 30034 10572\n",
            " 38724 17696   155 35408  7066  3503  5546 40990  7834  5641  1032 20227\n",
            " 20375 27458  4800 17824 30168 11627 41447 39707   135 33322 35078 30854\n",
            " 45398 10840  8229 31915 25557 14539  5523 14729   410 32783 26944 23907\n",
            " 14123 30633 40124 13868 37557 31424  1853 27924 32977  6044 15418  8785\n",
            "  9730  4304 21175 36949 47974 25908 17277 35489 32424 12481 46038 32360\n",
            " 44504 37398  2018  2735 29344 24825 24444   193 17894 11253 27692 24426\n",
            " 42220 49195 35249 20728 36644 14693 10004  4852 48541 31220  3269 49905\n",
            " 29175 41727  2599 25093 42534 44888 11049 39079 35374 49216 37362 43805\n",
            " 15935  3584  1392 11378 40919 23011 25013 23883 15811 18220 20949 22811\n",
            " 31076   766 22440 17560 39342 49789  2012 16315 36444  8879 16651 23534\n",
            "    92 14883  6468  2819 26981 47119 41403 11063 33651 46626 38089    69\n",
            " 40109  1337 27293  5675 16381  6086 42917 26440 16832 10234 18561 25176\n",
            " 25524 48316  7794 18812 26977 49767 49827  3250 20863 40578 48336 34546\n",
            " 37029 38540 44490  8721 42333 12600 37052  7022 44701 27386 31001 42050\n",
            " 48469 48756 41935 38800  4757 46309 44672 42835 36628 18996 32540 44937\n",
            " 48286 49852 39433 21312 23214 32840 12599 15011  9346 47181 45717 47871\n",
            " 28012 30664 47063 49953 38371  1399 16738  7497 21844 47770  6176 37771\n",
            " 26055  8406 48299 14292 32814 33840 33521 22374 12395 38727 36151 32567\n",
            " 30510  1416  1151 25368 24894 38009  6789 31168 10688 41893  4274  5687\n",
            "     8 29725  5278  3405 29882 20740 35588 44477  4502 31202 44373 36584\n",
            " 30294   562 46272  1314 38726 28295  7222 28955 24386 20719 15629 35268\n",
            " 44156 22758 41450  5787  7455 15927 37534 36551  9469 37710 16861 24185\n",
            " 18397 18305 36933 20209 16978  8940 36424 19530  7051 38458  2635 15951\n",
            " 12606 25258 28499 31187 39970 40609 45726 31590  3115  1822 32832 25327\n",
            " 49654 15617 45536 30504 19910 15573 31872  1056  9326 35766  8657 17220\n",
            " 24451 40691 28775 31037  9545 10346 47019 41829 13004 45325 24984 24095\n",
            " 30882 46033 26246 12866 28493 29600]\n"
          ]
        }
      ],
      "source": [
        "print(\"Airplane backdoor indices:\", airplane_flip_indices)\n",
        "print(\"Ship backdoor indices:\", ship_flip_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "537027ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "537027ec",
        "outputId": "e877a049-004c-4a80-d4d2-d37f2d947dcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
              "               RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
              "               ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=None)\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oxNkAMBAONXZ",
      "metadata": {
        "id": "oxNkAMBAONXZ"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # New added convolutional layer\n",
        "        self.conv5 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Flattened feature size = 512 * 1 * 1 = 512 (for 32x32 input after 5 pooling layers) anci\n",
        "        self.fc1 = nn.Linear(128 * 1 * 1, 512)    # first hidden layer\n",
        "        self.fc2 = nn.Linear(512, 256)            # second hidden layer (new)\n",
        "        self.fc3 = nn.Linear(256, 128)            # third hidden layer\n",
        "        #self.dropout = nn.Dropout(0.4)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)       # output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Feature extraction\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.pool(F.relu(self.bn5(self.conv5(x))))  # new conv layer\n",
        "\n",
        "        # Flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Classification head\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))   # new hidden layer\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        #x = self.dropout(x)\n",
        "        x = self.fc5(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f5fb03",
      "metadata": {
        "id": "94f5fb03"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size= 64, shuffle= False )\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "\n",
        "#model = models.resnet50(pretrained=True)\n",
        "#Replace the final layer (fc) for dataset (10 classes for CIFAR-10)\n",
        "#num_ftrs = model.fc.in_features\n",
        "#model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kX5Fe4clSSag",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX5Fe4clSSag",
        "outputId": "e59a7eb6-aa0d-4568-b287-098b44d40e2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 1.5550\n",
            "Epoch 2/50, Loss: 1.1794\n",
            "Epoch 3/50, Loss: 1.0245\n",
            "Epoch 4/50, Loss: 0.9232\n",
            "Epoch 5/50, Loss: 0.8411\n",
            "Epoch 6/50, Loss: 0.7802\n",
            "Epoch 7/50, Loss: 0.7272\n",
            "Epoch 8/50, Loss: 0.6909\n",
            "Epoch 9/50, Loss: 0.6569\n",
            "Epoch 10/50, Loss: 0.6287\n",
            "Epoch 11/50, Loss: 0.6054\n",
            "Epoch 12/50, Loss: 0.5797\n",
            "Epoch 13/50, Loss: 0.5654\n",
            "Epoch 14/50, Loss: 0.5472\n",
            "Epoch 15/50, Loss: 0.5301\n",
            "Epoch 16/50, Loss: 0.5141\n",
            "Epoch 17/50, Loss: 0.4964\n",
            "Epoch 18/50, Loss: 0.4790\n",
            "Epoch 19/50, Loss: 0.4743\n",
            "Epoch 20/50, Loss: 0.4632\n",
            "Epoch 21/50, Loss: 0.4432\n",
            "Epoch 22/50, Loss: 0.4417\n",
            "Epoch 23/50, Loss: 0.4288\n",
            "Epoch 24/50, Loss: 0.4172\n",
            "Epoch 25/50, Loss: 0.4132\n",
            "Epoch 26/50, Loss: 0.4064\n",
            "Epoch 27/50, Loss: 0.4035\n",
            "Epoch 28/50, Loss: 0.3900\n",
            "Epoch 29/50, Loss: 0.3813\n",
            "Epoch 30/50, Loss: 0.3758\n",
            "Epoch 31/50, Loss: 0.3698\n",
            "Epoch 32/50, Loss: 0.3651\n",
            "Epoch 33/50, Loss: 0.3573\n",
            "Epoch 34/50, Loss: 0.3492\n",
            "Epoch 35/50, Loss: 0.3485\n",
            "Epoch 36/50, Loss: 0.3406\n",
            "Epoch 37/50, Loss: 0.3346\n",
            "Epoch 38/50, Loss: 0.3307\n",
            "Epoch 39/50, Loss: 0.3248\n",
            "Epoch 40/50, Loss: 0.3246\n",
            "Epoch 41/50, Loss: 0.3184\n",
            "Epoch 42/50, Loss: 0.3154\n",
            "Epoch 43/50, Loss: 0.3072\n",
            "Epoch 44/50, Loss: 0.3045\n",
            "Epoch 45/50, Loss: 0.3031\n",
            "Epoch 46/50, Loss: 0.3006\n",
            "Epoch 47/50, Loss: 0.2959\n",
            "Epoch 48/50, Loss: 0.2885\n",
            "Epoch 49/50, Loss: 0.2920\n",
            "Epoch 50/50, Loss: 0.2853\n"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for images , labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)  #forw\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\") '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dLvX3lZLb1in",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLvX3lZLb1in",
        "outputId": "c17a4e4b-681a-4503-84de-044486df9474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc5): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-d7SPxoYmhY"
      },
      "id": "w-d7SPxoYmhY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SoQDrpKAa9LC",
      "metadata": {
        "id": "SoQDrpKAa9LC"
      },
      "outputs": [],
      "source": [
        "test_correct = 0\n",
        "test_total = 0\n",
        "#eval per class\n",
        "\n",
        "test_class_correct = [0]*10\n",
        "test_class_total = [0]*10\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)      #batch size\n",
        "        test_correct += (predicted == labels).sum().item() #tensor to int\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            test_class_correct[label] += (predicted[i] == label).item()  # int 1 if corr\n",
        "            test_class_total[label] += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_D1SwW9FM-Kx",
      "metadata": {
        "id": "_D1SwW9FM-Kx"
      },
      "outputs": [],
      "source": [
        "train_correct = 0\n",
        "train_total = 0\n",
        "train_class_correct = [0]*10\n",
        "train_class_total = [0]*10\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            train_class_correct[label] += (predicted[i] == label).item()\n",
        "            train_class_total[label] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LF4KNRN0aDnA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF4KNRN0aDnA",
        "outputId": "00950b11-de05-45af-a7c1-83608fe24274"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test  Accuracy (poisoned): 85.42%   |   Training  Accuracy (poisoned): 90.09%\n",
            " \n",
            "  Class             | Test  |   Train\n",
            "=============================================\n",
            "airplane             90.20% |           84.72%\n",
            "automobile           92.50% |           94.32%\n",
            "bird                 86.80% |           94.54%\n",
            "cat                  63.90% |           80.94%\n",
            "deer                 87.10% |           94.80%\n",
            "dog                  72.30% |           86.16%\n",
            "frog                 88.30% |           91.68%\n",
            "horse                92.20% |           97.14%\n",
            "ship                 88.20% |           80.44%\n",
            "truck                92.70% |           96.18%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test  Accuracy (poisoned): {100 * test_correct / test_total:.2f}%   |   Training  Accuracy (poisoned): {100 * train_correct / train_total:.2f}%\")\n",
        "print(f\" \")\n",
        "\n",
        "print(f\"{'  Class             |':} {'Test ':} | {'  Train':}\")\n",
        "print(\"=\"*45)\n",
        "\n",
        "#each claass  !\n",
        "for i in range(10):\n",
        "    acc = 100 * test_class_correct[i] / test_class_total[i] if test_class_total[i] > 0 else 0\n",
        "    acc_tr = 100 * train_class_correct[i] / train_class_total[i] if train_class_total[i] > 0 else 0\n",
        "    print(f\"{test_data.classes[i]:<10} {acc:15.2f}% | {acc_tr:15.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U9fA_4RBz8F8",
      "metadata": {
        "id": "U9fA_4RBz8F8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}